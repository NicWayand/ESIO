{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Plot forecast maps with all available models.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import struct\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import seaborn as sns\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "from esio import import_data\n",
    "import subprocess\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import timeit\n",
    "\n",
    "# General plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"talk\", font_scale=.8, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up local cluster for testing\n",
    "# client = Client()\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_init_times(fig_dir):\n",
    "    # Get list of all figures\n",
    "    fig_files = glob.glob(os.path.join(fig_dir,'*.png'))\n",
    "    init_times = list(reversed(sorted(list(set([os.path.basename(x).split('_')[3] for x in fig_files])))))\n",
    "    return init_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(ds_status=None, fig_dir=None, int_2_days_dict=None, NweeksUpdate=3):\n",
    "    # Get list of all figures\n",
    "    fig_files = glob.glob(os.path.join(fig_dir,'*.png'))\n",
    "    # For each figure\n",
    "    for fig_f in fig_files:\n",
    "        # Get the init_time from file name\n",
    "        cit = os.path.basename(fig_f).split('_')[3]\n",
    "        # Get the forecast int from file name\n",
    "        cft = int(os.path.basename(fig_f).split('_')[4].split('.')[0])\n",
    "        # Check if current it and ft were requested, otherwise skip\n",
    "        if (np.datetime64(cit) in ds_status.init_time.values) & (np.timedelta64(int_2_days_dict[cft]) in ds_status.fore_time.values):\n",
    "            # Always update the last 3 weeks (some models have lagg before we get them)\n",
    "            # Check if cit is one of the last NweeksUpdate init times in init_time\n",
    "            if (np.datetime64(cit) not in ds_status.init_time.values[-NweeksUpdate:]):\n",
    "                ds_status.status.loc[dict(init_time=cit, fore_time=int_2_days_dict[cft])] = 1\n",
    "        \n",
    "    return ds_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_PanArctic_Maps():\n",
    "    # Plotting Info\n",
    "    runType = 'forecast'\n",
    "    variables = ['sic']\n",
    "    metrics_all = {'sic':['anomaly','mean','SIP'], 'hi':['mean']}\n",
    "    updateAll = False\n",
    "    # Exclude some models\n",
    "    MME_NO = ['hcmr']\n",
    "\n",
    "    # Define Init Periods here, spaced by 7 days (aprox a week)\n",
    "    # Now\n",
    "    cd = datetime.datetime.now()\n",
    "    cd = datetime.datetime(cd.year, cd.month, cd.day) # Set hour min sec to 0. \n",
    "    # Hardcoded start date (makes incremental weeks always the same)\n",
    "    start_t = datetime.datetime(1950, 1, 1) # datetime.datetime(1950, 1, 1)\n",
    "    # Params for this plot\n",
    "    Ndays = 7 # time period to aggregate maps to (default is 7)\n",
    "    Npers = 5 # number of periods to plot (from current date) (default is 14)\n",
    "    NweeksUpdate = 3 # Always update the most recent NweeksUpdate periods\n",
    "    init_slice = np.arange(start_t, cd, datetime.timedelta(days=Ndays)).astype('datetime64[ns]')\n",
    "    init_slice = init_slice[-Npers:] # Select only the last Npers of periods (weeks) since current date\n",
    "\n",
    "    # Forecast times to plot\n",
    "    weeks = pd.to_timedelta(np.arange(0,5,1), unit='W')\n",
    "    months = pd.to_timedelta(np.arange(2,12,1), unit='M')\n",
    "    years = pd.to_timedelta(np.arange(1,2), unit='Y') - np.timedelta64(1, 'D') # need 364 not 365\n",
    "    slices = weeks.union(months).union(years).round('1d')\n",
    "    da_slices = xr.DataArray(slices, dims=('fore_time'))\n",
    "    da_slices.fore_time.values.astype('timedelta64[D]')\n",
    "    print(da_slices)\n",
    "\n",
    "    # Help conversion between \"week/month\" period used for figure naming and the actual forecast time delta value\n",
    "    int_2_days_dict = dict(zip(np.arange(0,da_slices.size), da_slices.values))\n",
    "    days_2_int_dict = {v: k for k, v in int_2_days_dict.items()}\n",
    "\n",
    "    #############################################################\n",
    "    # Load in Data\n",
    "    #############################################################\n",
    "\n",
    "    E = ed.EsioData.load()\n",
    "\n",
    "    # add missing info for climatology\n",
    "    E.model_color['climatology'] = (0,0,0)\n",
    "    E.model_linestyle['climatology'] = '--'\n",
    "    E.model_marker['climatology'] = '*'\n",
    "    E.model['climatology'] = {'model_label':'Clim. Trend'}\n",
    "    E.icePredicted['climatology'] = True\n",
    "\n",
    "    mod_dir = E.model_dir\n",
    "\n",
    "    # Get median ice edge by DOY\n",
    "    median_ice_fill = xr.open_mfdataset(os.path.join(E.obs_dir, 'NSIDC_0051', 'agg_nc', 'ice_edge.nc')).sic\n",
    "    # Get mean sic by DOY\n",
    "    mean_1980_2010_sic = xr.open_dataset(os.path.join(E.obs_dir, 'NSIDC_0051', 'agg_nc', 'mean_1980_2010_sic.nc')).sic\n",
    "    # Get average sip by DOY\n",
    "    mean_1980_2010_SIP = xr.open_dataset(os.path.join(E.obs_dir, 'NSIDC_0051', 'agg_nc', 'hist_SIP_1980_2010.nc')).sip    \n",
    "\n",
    "    # Get recent observations\n",
    "    ds_81 = xr.open_mfdataset(E.obs['NSIDC_0081']['sipn_nc']+'_yearly/*.nc', concat_dim='time', autoclose=True, parallel=True)#,\n",
    "\n",
    "\n",
    "    # Define models to plot\n",
    "    models_2_plot = list(E.model.keys())\n",
    "    models_2_plot = [x for x in models_2_plot if x not in ['piomas','MME','MME_NEW','uclsipn']] # remove some models\n",
    "    models_2_plot = [x for x in models_2_plot if E.icePredicted[x]] # Only predictive models\n",
    "    models_2_plot = ['MME']+models_2_plot # Add models to always plot at top\n",
    "    models_2_plot.insert(1, models_2_plot.pop(-1)) # Move climatology from last to second\n",
    "\n",
    "    # Get # of models and setup subplot dims\n",
    "    Nmod = len(models_2_plot) + 1#(+3 for obs, MME, and clim)\n",
    "    Nc = int(np.floor(np.sqrt(Nmod)))\n",
    "    # Max number of columns == 5 (plots get too small otherwise)\n",
    "    Nc = 5 #np.min([Nc,5])\n",
    "    Nr = int(np.ceil(Nmod/Nc))\n",
    "    print(Nr, Nc, Nmod)\n",
    "    assert Nc*Nr>=Nmod, 'Need more subplots'\n",
    "\n",
    "\n",
    "    for cvar in variables:\n",
    "\n",
    "#         # Load in all metrics for given variable\n",
    "#         ds_m = import_data.load_MME_by_init_end(E=E, runType=runType, variable=cvar, \n",
    "#                                     metrics=metrics_all[cvar], \n",
    "#                                     init_range=[init_slice[0],init_slice[-1]])\n",
    "\n",
    "#         # Drop models that we don't evaluate (i.e. monthly means)\n",
    "#         models_keep = [x for x in ds_m.model.values if x not in ['noaasipn','modcansipns_3','modcansipns_4']]\n",
    "#         ds_m = ds_m.sel(model=models_keep)\n",
    "#         # Get list of dynamical models that are not observations\n",
    "#         dynamical_Models = [x for x in ds_m.model.values if x not in ['Observed','climatology','dampedAnomaly','dampedAnomalyTrend']]\n",
    "#         # Get list of all models\n",
    "#         all_Models = [x for x in ds_m.model.values if x not in ['Observed']]\n",
    "#         # Add MME\n",
    "#         MME_avg = ds_m.sel(model=dynamical_Models).mean(dim='model') # only take mean over dynamical models\n",
    "#         MME_avg.coords['model'] = 'MME'\n",
    "#         ds_ALL = xr.concat([ds_m, MME_avg], dim='model')\n",
    "        \n",
    "#         # Save to Zarr\n",
    "#         ds_ALL.to_zarr('/home/disk/sipn/nicway/data/model/zarr/sic.zarr', mode='w')\n",
    "#         xr.exit()\n",
    "\n",
    "        ds_All = xr.open_zarr('/home/disk/sipn/nicway/data/model/zarr/sic.zarr')\n",
    "\n",
    "        # Define fig dir and make if doesn't exist\n",
    "        fig_dir = os.path.join(E.fig_dir, 'model', 'all_model', cvar, 'maps_weekly_NEW')\n",
    "        if not os.path.exists(fig_dir):\n",
    "            os.makedirs(fig_dir)\n",
    "\n",
    "        # Make requested dataArray as specified above\n",
    "        ds_status = xr.DataArray(np.ones((init_slice.size, da_slices.size))*np.NaN, \n",
    "                                 dims=('init_time','fore_time'), \n",
    "                                 coords={'init_time':init_slice,'fore_time':da_slices}) \n",
    "        ds_status.name = 'status'\n",
    "        ds_status = ds_status.to_dataset()\n",
    "\n",
    "\n",
    "        # Check what plots we already have\n",
    "        if not updateAll:\n",
    "            print(\"Removing figures we have already made\")\n",
    "            ds_status = update_status(ds_status=ds_status, fig_dir=fig_dir, int_2_days_dict=int_2_days_dict, NweeksUpdate=NweeksUpdate)\n",
    "\n",
    "        \n",
    "        print(ds_status.status.values)\n",
    "        # Drop IC/FT we have already plotted (orthoginal only)\n",
    "        ds_status = ds_status.where(ds_status.status.sum(dim='fore_time')<ds_status.fore_time.size, drop=True)\n",
    "\n",
    "        print(\"Starting plots...\")\n",
    "        # For each init_time we haven't plotted yet\n",
    "        \n",
    "        for it in ds_status.init_time.values: \n",
    "            start_time_cmod = timeit.default_timer()\n",
    "            print(it)\n",
    "            it_start = it-np.timedelta64(Ndays,'D') + np.timedelta64(1,'D') # Start period for init period (it is end of period). Add 1 day because when\n",
    "            # we select using slice(start,stop) it is inclusive of end points. So here we are defining the start of the init AND the start of the valid time.\n",
    "            # So we need to add one day, so we don't double count. \n",
    "\n",
    "            # For each forecast time we haven't plotted yet\n",
    "            ft_to_plot = ds_status.sel(init_time=it)\n",
    "            ft_to_plot = ft_to_plot.where(ft_to_plot.isnull(), drop=True).fore_time\n",
    "\n",
    "            for ft in ft_to_plot.values: \n",
    "\n",
    "                print(ft.astype('timedelta64[D]'))\n",
    "                cs_str = format(days_2_int_dict[ft], '02') # Get index of current forcast week\n",
    "                week_str = format(int(ft.astype('timedelta64[D]').astype('int')/Ndays) , '02') # Get string of current week\n",
    "                cdoy_end = pd.to_datetime(it + ft).timetuple().tm_yday # Get current day of year end for valid time\n",
    "                cdoy_start = pd.to_datetime(it_start + ft).timetuple().tm_yday  # Get current day of year end for valid time\n",
    "                it_yr = str(pd.to_datetime(it).year) \n",
    "                it_m = str(pd.to_datetime(it).month)\n",
    "\n",
    "                # Get datetime64 of valid time start and end\n",
    "                valid_start = it_start + ft\n",
    "                valid_end = it + ft\n",
    "\n",
    "                # Loop through variable of interest + any metrics (i.e. SIP) based on that\n",
    "                for metric in metrics_all[cvar]:\n",
    "\n",
    "                    # Set up plotting info\n",
    "                    if cvar=='sic':\n",
    "                        if metric=='mean':\n",
    "                            cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Blues_r\", 10))\n",
    "                            cmap_c.set_bad(color = 'lightgrey')\n",
    "                            c_label = 'Sea Ice Concentration (-)'\n",
    "                            c_vmin = 0\n",
    "                            c_vmax = 1\n",
    "                        elif metric=='SIP':\n",
    "                            cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"orange\",\"red\",\"#990000\"])\n",
    "                            cmap_c.set_bad(color = 'lightgrey')\n",
    "                            c_label = 'Sea Ice Probability (-)'\n",
    "                            c_vmin = 0\n",
    "                            c_vmax = 1\n",
    "                        elif metric=='anomaly':\n",
    "    #                         cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"coolwarm\", 9))\n",
    "                            cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"white\",\"blue\"])\n",
    "                            cmap_c.set_bad(color = 'lightgrey')\n",
    "                            c_label = 'SIC Anomaly to 1980-2010 Mean'\n",
    "                            c_vmin = -1\n",
    "                            c_vmax = 1\n",
    "\n",
    "                    elif cvar=='hi':\n",
    "                        if metric=='mean':\n",
    "                            cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Reds_r\", 10))\n",
    "                            cmap_c.set_bad(color = 'lightgrey')\n",
    "                            c_label = 'Sea Ice Thickness (m)'\n",
    "                            c_vmin = 0\n",
    "                            c_vmax = None\n",
    "                    else:\n",
    "                        raise ValueError(\"cvar not found.\") \n",
    "\n",
    "\n",
    "                    # New Plot\n",
    "                    #start_time_plot = timeit.default_timer()\n",
    "                    (f, axes) = ice_plot.multi_polar_axis(ncols=Nc, nrows=Nr, Nplots=Nmod)\n",
    "\n",
    "\n",
    "                    ############################################################################\n",
    "                    #                               OBSERVATIONS                               #\n",
    "                    ############################################################################\n",
    "\n",
    "                    # Plot Obs (if available)\n",
    "                    ax_num = 0\n",
    "                    axes[ax_num].set_title('Observed')\n",
    "\n",
    "                    try:\n",
    "                        da_obs_c = ds_ALL[metric].sel(model='Observed',init_end=it, fore_time=ft)\n",
    "                        haveObs = True\n",
    "                    except:\n",
    "                        haveObs = False\n",
    "\n",
    "                    # If obs then plot\n",
    "                    if haveObs:\n",
    "\n",
    "                        da_obs_c.plot.pcolormesh(ax=axes[ax_num], x='lon', y='lat', \n",
    "                                              transform=ccrs.PlateCarree(),\n",
    "                                              add_colorbar=False,\n",
    "                                              cmap=cmap_c,\n",
    "                                              vmin=c_vmin, vmax=c_vmax)\n",
    "                        axes[ax_num].set_title('Observed')     \n",
    "                    else: # When were in the future (or obs are missing)\n",
    "                        if metric=='SIP': # Plot this historical mean SIP \n",
    "                            print(\"plotting hist obs SIP\")\n",
    "                            da_obs_c = mean_1980_2010_SIP.isel(time=slice(cdoy_start,cdoy_end)).mean(dim='time')\n",
    "                            da_obs_c.plot.pcolormesh(ax=axes[ax_num], x='lon', y='lat', \n",
    "                              transform=ccrs.PlateCarree(),\n",
    "                              add_colorbar=False,\n",
    "                              cmap=cmap_c,\n",
    "                              vmin=c_vmin, vmax=c_vmax)\n",
    "                            axes[ax_num].set_title('Hist. Obs.')\n",
    "\n",
    "                    ############################################################################\n",
    "                    #                    Plot all models                                       #\n",
    "                    ############################################################################\n",
    "\n",
    "                    for (i, cmod) in enumerate(models_2_plot):\n",
    "                        #print(cmod)\n",
    "                        i = i+1 # shift for obs\n",
    "                        axes[i].set_title(E.model[cmod]['model_label'])\n",
    "\n",
    "                        # Select current model to plot\n",
    "                        try:\n",
    "                            ds_model = ds_ALL[metric].sel(model=cmod,init_end=it, fore_time=ft)\n",
    "                            haveMod = True\n",
    "                        except:\n",
    "                            haveMod = False\n",
    "\n",
    "                        # Plot\n",
    "                        if haveMod:\n",
    "                            p = ds_model.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                              transform=ccrs.PlateCarree(),\n",
    "                                              add_colorbar=False,\n",
    "                                              cmap=cmap_c,\n",
    "                                              vmin=c_vmin, vmax=c_vmax)\n",
    "\n",
    "                            axes[i].set_title(E.model[cmod]['model_label'])\n",
    "\n",
    "                            # Clean up for current model\n",
    "                            ds_model = None\n",
    "\n",
    "                    # Make pretty\n",
    "                    f.subplots_adjust(right=0.8)\n",
    "                    cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "                    if p:\n",
    "                        cbar = f.colorbar(p, cax=cbar_ax, label=c_label)\n",
    "                        if metric=='anomaly':\n",
    "                            cbar.set_ticks(np.arange(-1,1.1,0.2))\n",
    "                        else:\n",
    "                            cbar.set_ticks(np.arange(0,1.1,0.1))\n",
    "\n",
    "                    # Set title of all plots\n",
    "                    init_time_2 =  pd.to_datetime(it).strftime('%Y-%m-%d')\n",
    "                    init_time_1 =  pd.to_datetime(it_start).strftime('%Y-%m-%d')\n",
    "                    valid_time_2 = pd.to_datetime(it+ft).strftime('%Y-%m-%d')\n",
    "                    valid_time_1 = pd.to_datetime(it_start+ft).strftime('%Y-%m-%d')\n",
    "                    plt.suptitle('Initialization Time: '+init_time_1+' to '+init_time_2+'\\n Valid Time: '+valid_time_1+' to '+valid_time_2,\n",
    "                                 fontsize=15) # +'\\n Week '+week_str\n",
    "                    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "                    # Save to file\n",
    "                    f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+init_time_2+'_'+cs_str+'.png')\n",
    "                    f.savefig(f_out,bbox_inches='tight', dpi=200)\n",
    "                    print(\"saved \", f_out)\n",
    "                    #print(\"Figure took  \", (timeit.default_timer() - start_time_plot)/60, \" minutes.\")\n",
    "                    \n",
    "                    # Mem clean up\n",
    "                    plt.close(f)\n",
    "                    da_obs_c = None\n",
    "\n",
    "            # Done with current it\n",
    "            print(\"Took \", (timeit.default_timer() - start_time_cmod)/60, \" minutes.\")\n",
    "\n",
    "\n",
    "    # Update json file\n",
    "    json_format = get_figure_init_times(fig_dir)\n",
    "    json_dict = [{\"date\":cd,\"label\":cd} for cd in json_format]\n",
    "\n",
    "    json_f = os.path.join(fig_dir, 'plotdates_current.json')\n",
    "    with open(json_f, 'w') as outfile:\n",
    "        json.dump(json_dict, outfile)\n",
    "\n",
    "    # Make into Gifs\n",
    "    # TODO: make parallel, add &\n",
    "    for cit in json_format:\n",
    "        subprocess.call(str(\"/home/disk/sipn/nicway/python/ESIO/scripts/makeGif.sh \" + fig_dir + \" \" + cit), shell=True)\n",
    "\n",
    "    print(\"Finished plotting panArctic Maps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Start up Client\n",
    "    client = Client(n_workers=8)\n",
    "#     dask.config.set(scheduler='threads')  # overwrite default with threaded scheduler\n",
    "    \n",
    "    # Call function\n",
    "    Update_PanArctic_Maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run below in case we need to just update the json file and gifs\n",
    "\n",
    "\n",
    "# fig_dir = '/home/disk/sipn/nicway/public_html/sipn/figures/model/all_model/sic/maps_weekly'\n",
    "# json_format = get_figure_init_times(fig_dir)\n",
    "# json_dict = [{\"date\":cd,\"label\":cd} for cd in json_format]\n",
    "\n",
    "# json_f = os.path.join(fig_dir, 'plotdates_current.json')\n",
    "# with open(json_f, 'w') as outfile:\n",
    "#     json.dump(json_dict, outfile)\n",
    "\n",
    "# # Make into Gifs\n",
    "# # TODO fig_dir hardcoded to current variable\n",
    "# for cit in json_format:\n",
    "#     subprocess.call(str(\"/home/disk/sipn/nicway/python/ESIO/scripts/makeGif.sh \" + fig_dir + \" \" + cit), shell=True)\n",
    "\n",
    "# print(\"Finished plotting panArctic Maps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.4 esio",
   "language": "python",
   "name": "esio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
